import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, BatchNormalization, LeakyReLU, \
    Reshape, Conv2DTranspose, LeakyReLU, Layer
import tensorflow_gan as tfgan
import tensorflow_hub as hub

import numpy as np

import os
import argparse
import time

from imageio import imwrite
from generator import UnetGenerator, AutoEncoder
from preprocess import load_image_batch, random_jitter_and_mirroring

# Killing optional CPU driver warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

gpu_available = tf.test.is_gpu_available()
print("GPU Available: ", gpu_available)

## --------------------------------------------------------------------------------------

parser = argparse.ArgumentParser(description='DCGAN')

parser.add_argument('--img-dir', type=str, default='../../UnetGenerator/data/facades',
                            help='Data where testing images live')

parser.add_argument('--out-dir', type=str, default='./output',
                            help='Data where sampled output images will be written')

parser.add_argument('--mode', type=str, default='train',
                            help='Can be "train" or "test"')

parser.add_argument('--restore-checkpoint', action='store_true',
                            help='Use this flag if you want to resuming training from a previously-saved checkpoint')

parser.add_argument('--z-dim', type=int, default=100,
                            help='Dimensionality of the latent space')

parser.add_argument('--batch-size', type=int, default=1,
                            help='Sizes of image batches fed through the network')

parser.add_argument('--num-data-threads', type=int, default=2,
                    help='Number of threads to use when loading & pre-processing training images')

parser.add_argument('--num-epochs', type=int, default=200,
                    help='Number of passes through the training data to make before stopping')

parser.add_argument('--learn-rate', type=float, default=0.0002,
                    help='Learning rate for Adam optimizer')

parser.add_argument('--beta1', type=float, default=0.5,
                    help='"beta1" parameter for Adam optimizer')

parser.add_argument('--num-gen-updates', type=int, default=2,
                    help='Number of generator updates per discriminator update')

parser.add_argument('--log-every', type=int, default=128,
                    help='Print losses after every [this many] training iterations')

parser.add_argument('--save-every', type=int, default=50,
                    help='Save the state of the network after every [this many] training iterations')

parser.add_argument('--device', type=str, default='GPU:0' if gpu_available else 'CPU:0',
                    help='specific the device of computation eg. CPU:0, GPU:0, GPU:1, GPU:2, ... ')

args = parser.parse_args()

## --------------------------------------------------------------------------------------

# Numerically stable logarithm function
def log(x):
    """
    Finds the stable log of x

    :param x: 
    """
    return tf.math.log(tf.maximum(x, 1e-5))

## --------------------------------------------------------------------------------------

# For evaluating the quality of generated images
# Frechet Inception Distance measures how similar the generated images are to the real ones
# https://nealjean.com/ml/frechet-inception-distance/
# Lower is better
module = tf.keras.Sequential([hub.KerasLayer("https://tfhub.dev/google/tf2-preview/inception_v3/classification/4", output_shape=[1001])])
def fid_function(real_image_batch, generated_image_batch):
    """
    Given a batch of real images and a batch of generated images, this function pulls down a pre-trained inception 
    v3 network and then uses it to extract the activations for both the real and generated images. The distance of 
    these activations is then computed. The distance is a measure of how "realistic" the generated images are.

    :param real_image_batch: a batch of real images from the dataset, shape=[batch_size, height, width, channels]
    :param generated_image_batch: a batch of images generated by the generator network, shape=[batch_size, height, width, channels]

    :return: the inception distance between the real and generated images, scalar
    """
    INCEPTION_IMAGE_SIZE = (299, 299)
    real_resized = tf.image.resize(real_image_batch, INCEPTION_IMAGE_SIZE)
    fake_resized = tf.image.resize(generated_image_batch, INCEPTION_IMAGE_SIZE)
    module.build([None, 299, 299, 3])
    real_features = module(real_resized)
    fake_features = module(fake_resized)
    return tfgan.eval.frechet_classifier_distance_from_activations(real_features, fake_features)

k_init=tf.keras.initializers.TruncatedNormal(stddev=0.02)
g_init=tf.keras.initializers.TruncatedNormal(mean=1.0, stddev=0.02)
def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(Conv2D(
        filters=64, kernel_size=(5, 5), strides=(2, 2), padding="same",
        input_shape=(64, 64, 3), kernel_initializer=k_init))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2D(
        filters=128, kernel_size=(5, 5), strides=(2, 2), padding="same", 
        use_bias=False, kernel_initializer=k_init))
    model.add(BatchNormalization(gamma_initializer=g_init))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2D(
        filters=256, kernel_size=(5, 5), strides=(2, 2), padding="same",
        use_bias=False, kernel_initializer=k_init))
    model.add(BatchNormalization(gamma_initializer=g_init))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2D(
        filters=512, kernel_size=(5, 5), strides=(2, 2), padding="same",
        use_bias=False, kernel_initializer=k_init))
    model.add(BatchNormalization(gamma_initializer=g_init))
    model.add(LeakyReLU(alpha=0.2))
    # Get some help from https://sthalles.github.io/intro-to-gans/
    model.add(Flatten())
    model.add(Dense(1, kernel_initializer=k_init))
    model.add(Activation("sigmoid"))

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.learn_rate, beta_1=args.beta1),
        loss='binary_crossentropy')
    return model
    
## --------------------------------------------------------------------------------------
# Get some help from:
# https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a
# Code adapted from:
# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html
optimizer = tf.keras.optimizers.Adam(learning_rate=args.learn_rate, beta_1=args.beta1)
# Code copied from the GAN lab.
def optimize(tape: tf.GradientTape, model: tf.keras.Model, loss: tf.Tensor) -> None:
  """ This optimizes a model with respect to its loss

  Inputs:
  - tape: the Gradient Tape
  - model: the model to be trained
  - loss: the model's loss
  """
  # calculate the gradients our input model and apply them
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

# Train the model for one epoch.
def train(generator, discriminator, dataset_iterator, manager):
    """
    Train the model for one epoch. Save a checkpoint every 500 or so batches.

    :param generator: generator model
    :param discriminator: discriminator model
    :param dataset_ierator: iterator over dataset, see preprocess.py for more information
    :param manager: the manager that handles saving checkpoints by calling save()

    :return: The average FID score over the epoch
    """
    start_time = time.time()
    fids = []
    y_true, y_pred = [], []
    # Loop over our data until we run out
    for iteration, image_pairs in enumerate(dataset_iterator):
        image_pairs = random_jitter_and_mirroring(image_pairs)
        input_, ground_truth = tf.split(image_pairs, 2, 2)
        with tf.GradientTape(persistent=True) as tape:
            generated_output = generator(input_)
            lossG = generator.loss_function(None, generated_output, ground_truth)

        optimize(tape, generator, lossG)
        # otimize(tape, discriminator, lossD)
        y_true.append(ground_truth)
        y_pred.append(generated_output)
        # Save
        if iteration > 0 and iteration % args.save_every == 0:
            manager.save()
            # Calculate inception distance and track the fid in order
            # to return the average
            fids.append(fid_function(tf.concat(y_true, 0), tf.concat(y_pred, 0)))
            y_true.clear()
            y_pred.clear()
            print('**** (INCEPTION DISTANCE, lossG): (%g, %g) ****' % (fids[-1], lossG))
    print("---- Time Taken for One Epoch: %g ----" % (time.time() - start_time))
    return sum(fids) / float(len(fids))

# Test the model by generating some samples.
def test(generator, dataset_iterator):
    """
    Test the model.

    :param generator: generator model

    :return: None
    """
    for i, image_pairs in enumerate(dataset_iterator):
        # Sample a batch of random images
        input_, ground_truth = tf.split(image_pairs, 2, 2)
        ### Below, we've already provided code to save these generated images to files on disk
        img = tf.concat([input_, ground_truth, generator(input_)], 2).numpy()
        assert(np.all(-1.0 <= img) and np.all(img <= 1.0))
        # Rescale the image from (-1, 1) to (0, 255)
        img = ((img / 2) + 0.5) * 255
        img = img.astype(np.uint8)
        # Save images to disk
        s = args.out_dir+'/'+str(i)+'.png'
        imwrite(s, img[0])

## --------------------------------------------------------------------------------------

def main():
    # Load a batch of images (to feed to the discriminator)
    dataset_iterator = load_image_batch(args.img_dir + '/' + args.mode, batch_size=args.batch_size, n_threads=args.num_data_threads)

    # Initialize generator and discriminator models
    # generator = UnetGenerator(3, 3)
    generator = AutoEncoder(3, 3)
    discriminator = make_discriminator_model()

    # For saving/loading models
    checkpoint_dir = './checkpoints'
    checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
    checkpoint = tf.train.Checkpoint(generator=generator, discriminator=discriminator)
    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)
    # Ensure the output directory exists
    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)

    if args.restore_checkpoint or args.mode == 'test':
        # restores the latest checkpoint using from the manager
        checkpoint.restore(manager.latest_checkpoint) 

    try:
        # Specify an invalid GPU device
        with tf.device('/device:' + args.device):
            if args.mode == 'train':
                for epoch in range(0, args.num_epochs):
                    print('========================== EPOCH %d  ==========================' % epoch)
                    avg_fid = train(generator, discriminator, dataset_iterator, manager)
                    print("Average FID for Epoch: " + str(avg_fid))
                    # Save at the end of the epoch, too
                    print("**** SAVING CHECKPOINT AT END OF EPOCH ****")
                    manager.save()
            if args.mode == 'test':
                test(generator, dataset_iterator)
    except RuntimeError as e:
        print(e)

if __name__ == '__main__':
   main()


